{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Machine Learning Framework.ipynb","provenance":[{"file_id":"1KjyOCiQCSeARvFw5ED5Z4yEW0LmRmQ9h","timestamp":1646018324967},{"file_id":"1KCA1stOLvtcAu9jaPRm53ym-g3AZI5Qb","timestamp":1643247245540},{"file_id":"1UpqtCk7LZz25JRI3pTrG_HsBipJXA4zJ","timestamp":1642277109422}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**This script creates a class for classical machine learning in time series data. **"],"metadata":{"id":"L_iGAhWrbt3c"}},{"cell_type":"markdown","source":["## Standard Import\n"],"metadata":{"id":"Ob16OP8dO8gC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"w9kdl-oSHWXW"},"outputs":[],"source":["## Standard imports\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import sklearn\n","\n","import os\n","import math\n","\n","%matplotlib inline\n"]},{"cell_type":"code","source":["from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","from sklearn import linear_model\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neural_network import MLPClassifier"],"metadata":{"id":"bMPtUOt-QE8Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# DATA_DIR=\"/content/drive/MyDrive/IAQF - Five+1 Guys/2022/Data\""],"metadata":{"id":"N04zSYF6SO4s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ML Framework class (need to pass dataset and model)"],"metadata":{"id":"j0i4xYy5bpFl"}},{"cell_type":"code","source":["class MLFramework():\n","  def __init__(self, target_var:str, features:list , df = None, DF_DIR: str = None):\n","    if df is not None:\n","      self.df = df\n","    else:\n","      self.df = pd.read_csv(DF_DIR, index_col=0, parse_dates=True)\n","      self.df.sort_index(inplace=True)\n","    self.target_var = target_var\n","    self.features = features\n","    self.tsSplit = None\n","  \n","  def standardFlow(self, model, metric_CV=None):\n","    self.train_test_split()\n","    self.setModel(model)\n","    CVScore = self.CVScore_TS(metric_CV = metric_CV)\n","    print(\"CV Score: \",CVScore)\n","    print(\"Insample Result: \", self.insampleResult())\n","    print(\"Outsample Result: \", self.outsampleResult())\n","    print(\"Remark: model is fitted with the whole trainning dataset \")\n","\n","  def insampleResult(self):\n","    self.model.fit(self.X_train,self.y_train)\n","    return self.model.score(self.X_train, self.y_train)\n","\n","  def outsampleResult(self):\n","    return self.model.score(self.X_test, self.y_test)\n","\n","\n","  def train_test_split(self, StDate_test = pd.to_datetime('2018-01-01'), ratio = None):\n","    if ratio is not None:\n","      nrow = self.df.shape[0]\n","      StDate_test = self.df.iloc[int(nrow*ratio)].index\n","    else:\n","      if self.df.index.max() < StDate_test:\n","        raise ValueError('MLFramework.train_test_split: Incorrect StDate_test')\n","      \n","    \n","    train_idx = self.df.index < StDate_test\n","    # self.X_train = self.df.loc[train_idx,self.features].values\n","    # self.X_test = self.df.loc[~train_idx,self.features].values\n","    # self.y_train = self.df.loc[train_idx,self.target_var].values\n","    # self.y_test = self.df.loc[~train_idx,self.target_var].values\n","\n","    self.X_train = self.df.loc[train_idx,self.features]\n","    self.X_test = self.df.loc[~train_idx,self.features]\n","    self.y_train = self.df.loc[train_idx,self.target_var]\n","    self.y_test = self.df.loc[~train_idx,self.target_var]\n","\n","  def setModel(self, model):\n","    self.model = model\n","\n","  def CVScore_TS(self, metric_CV=None, n_splits=5):\n","    # metric_cv: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n","    self.metric_CV = metric_CV\n","    self.tsSplit = TimeSeriesSplit(n_splits=n_splits)\n","    cv = self.tsSplit.split(self.X_train)\n","    return cross_val_score(self.model, self.X_train , self.y_train , cv = cv, scoring = metric_CV )\n","\n","  def gridSearch_TS(self, parameters:dict, metric_CV=None, n_splits=5):\n","    if self.tsSplit is None:\n","      self.tsSplit = TimeSeriesSplit(n_splits=n_splits)\n","    cv = self.tsSplit.split(self.X_train)\n","\n","    self.gs =  GridSearchCV(self.model, parameters, scoring = metric_CV, cv = cv)\n","    self.gs.fit(self.X_train, self.y_train)\n","    \n","    print(\"Best param from Grid Search:\", self.gs.best_params_)\n","    print(\"CV score for the best param:\", self.gs.best_score_)\n","    return pd.DataFrame(self.gs.cv_results_)\n","\n","  def target_transform_cat(self):\n","    self.y_train_trans = pd.get_dummies(self.y_train)[[-1,0,1]]\n","    self.y_test_trans = pd.get_dummies(self.y_test)[[-1,0,1]]\n","    if hasattr(self, 'y_val'):\n","      self.y_val_trans = pd.get_dummies(self.y_val)[[-1,0,1]]\n","    # return self.y_train_trans, self.y_test_trans \n","  \n","  def train_val_test_split(self, StDate_val = pd.to_datetime('2014-01-01'), StDate_test = pd.to_datetime('2018-01-01')):\n","    train_idx = self.df.index < StDate_val\n","    val_idx = (self.df.index >= StDate_val) & (self.df.index < StDate_test)\n","    test_idx = self.df.index >= StDate_test\n","\n","\n","    self.X_train = self.df.loc[train_idx,self.features]\n","    self.X_val = self.df.loc[val_idx,self.features]\n","    self.X_test = self.df.loc[test_idx,self.features]\n","\n","    self.y_train = self.df.loc[train_idx,self.target_var]\n","    self.y_val = self.df.loc[val_idx, self.target_var]\n","    self.y_test = self.df.loc[test_idx,self.target_var]\n","\n","    return self.X_train,  self.X_val, self.X_test, self.y_train, self.y_val, self.y_test"],"metadata":{"id":"j0IdOr6-hA6J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df = pd.read_csv(os.path.join(DATA_DIR,'Russell3000.csv'), index_col=0, parse_dates=True)\n","# target_var='Adj Close'\n","# features = ['Open','High','Low']\n","\n","# model = linear_model.Lasso(alpha=0.01)\n","\n","# ML_trial = MLFramework( target_var=target_var, features=features , df =df)\n","# ML_trial.standardFlow(model = model)\n"],"metadata":{"id":"5YxgdpiVa6WF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# params = {'alpha':np.arange(0.001,1,0.01)}\n","# ML_trial.gridSearch_TS(params)"],"metadata":{"id":"0_kNW71pDk5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# np.arange(0.001,1,0.01)"],"metadata":{"id":"sYk4_HstD3u1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Features"],"metadata":{"id":"wivPijow_lne"}},{"cell_type":"markdown","source":["## "],"metadata":{"id":"DVCKaZnS_ogH"}},{"cell_type":"code","source":["# class features():\n","#   def __init__(self,df)\n","#   def return()"],"metadata":{"id":"1g2XBiwAO7dJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Read dataset for checking"],"metadata":{"id":"wlBqWBZCswbg"}},{"cell_type":"code","source":["# file = os.path.join(DATA_DIR,'DailyData.csv')\n","# test=pd.read_csv(file, parse_dates=True, index_col=0)"],"metadata":{"id":"U7nhNgyis0eQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test.describe()"],"metadata":{"id":"r_iK3lYyt1x6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test.loc[test.isna().any(axis=1),test.isna().any(axis=0)]"],"metadata":{"id":"gLlqMvZqt89h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test.dtypes"],"metadata":{"id":"C-LvXiY4uaZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# filename = os.path.join(DATA_DIR,'Russell3000TotalReturn.xlsx')\n","# test2 = pd.read_excel(filename,skiprows=6,index_col=0,parse_dates=True)\n","# test2"],"metadata":{"id":"wnj5G5FSvLQn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test2.index"],"metadata":{"id":"vui97_B-vo8L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test2.index[0]"],"metadata":{"id":"Kxi4tam4wJUr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Try with labels"],"metadata":{"id":"P2vdTsYzhJX5"}},{"cell_type":"code","source":["# df = pd.read_csv(os.path.join(DATA_DIR,'Russell3000.csv'), index_col=0, parse_dates=True)\n","# df.head()\n"],"metadata":{"id":"8hHNk95Q_m2w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Method 1: detect an increase/decrease of at least r% in a future horizon of n units time.\n","Let up=0.1, and down=-0.14. Look ahead 10 days."],"metadata":{"id":"x0vFSlVfiyXr"}},{"cell_type":"code","source":["# df['RET10'] = df[\"Adj Close\"].shift(-10) / df[\"Adj Close\"] - 1 #return of future 10 days\n","\n","# def sig(value, up, down):\n","#   if value > up:\n","#     return 1\n","#   elif value < down:\n","#     return -1\n","#   return 0\n","\n","# up = 0.1\n","# down = -0.15\n","\n","# df['POS'] = df['RET10'].apply(sig, args=(up, down,))\n","# df"],"metadata":{"id":"QJ99hgReiv34"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df['POS'].cumsum().plot()"],"metadata":{"id":"DzS_sRSLjZNv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# target_var='POS'\n","# features = ['Open','High','Low']"],"metadata":{"id":"Ixm68UUGjQxE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = MLPClassifier(random_state=1, max_iter=300)\n","\n","# ML_trial = MLFramework( target_var=target_var, features=features , df =df)\n","# ML_trial.standardFlow(model = model)"],"metadata":{"id":"kMfYGtW-ic9j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Method 2: Lunde and Timmermann"],"metadata":{"id":"80vD2X74kAr_"}},{"cell_type":"code","source":["# def defbuallbear(df, varname, lambda1, lambda2):\n","#   peaks = [df.index[0]]\n","#   troughs = [df.index[0]]\n","#   flag = 1\n","#   for i in range(df.shape[0]):\n","#     if flag == 1:\n","#       if df.iloc[i][varname] > df.loc[peaks[-1]][varname]:\n","#         peaks[-1] = df.index[i]\n","#       elif df.iloc[i][varname] < (1 - lambda2) * df.loc[peaks[-1]][varname]:\n","#         troughs.append(df.index[i])\n","#         flag = -1\n","#     else:\n","#       if df.iloc[i][varname] < df.loc[troughs[-1]][varname]:\n","#         troughs[-1] = df.index[i]\n","#       elif df.iloc[i][varname] > (1 + lambda1) * df.loc[troughs[-1]][varname]:\n","#         peaks.append(df.index[i])\n","#         flag = 1\n","#   df[\"State\"] = np.nan\n","#   df.loc[peaks, \"State\"] = 1\n","#   df.loc[troughs, \"State\"] = -1\n","#   df.fillna(method=\"bfill\", inplace=True)\n","#   return df"],"metadata":{"id":"CjaqWVkCj5wY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df = defbullbear(df, \"Adj Close\", 0.1, 0.05) # lambda1=0.1, lambda2=0.05"],"metadata":{"id":"f7YK5lGdkAJi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # create figure and axis objects with subplots()\n","# fig,ax = plt.subplots(figsize=(20,12))\n","# # make a plot\n","# ax.plot(df['Adj Close'], color=\"red\", marker=\"o\")\n","# # set x-axis label\n","# ax.set_xlabel(\"year\",fontsize=14)\n","# # set y-axis label\n","# ax.set_ylabel(\"Close\",color=\"red\",fontsize=14)\n","\n","# # twin object for two different y-axis on the sample plot\n","# ax2=ax.twinx()\n","# # make a plot with different y-axis using second axis object\n","# ax2.plot(df[\"State\"], color=\"blue\",marker=\"o\")\n","# ax2.set_ylabel(\"State\",color=\"blue\",fontsize=14)\n","# plt.show()"],"metadata":{"id":"zC3hux6NkAMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df[\"State\"].hist()"],"metadata":{"id":"HA-xGM5LkAPM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# target_var='State'\n","# features = ['Open','High','Low']\n","\n","# model = linear_model.Lasso(alpha=0.01)\n","\n","# ML_trial = MLFramework( target_var=target_var, features=features , df =df)\n","# ML_trial.standardFlow(model = model)"],"metadata":{"id":"_Wa8ZpJbkdpn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = MLPClassifier(random_state=1, max_iter=300)\n","\n","# ML_trial = MLFramework( target_var=target_var, features=features , df =df)\n","# ML_trial.standardFlow(model = model)"],"metadata":{"id":"UwOKlv8fk1BV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Kk42G0Gu-UVg"},"execution_count":null,"outputs":[]}]}